{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fi0BfJvYUWGD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, StratifiedKFold, KFold, GroupKFold, TimeSeriesSplit,\n",
        "    LeaveOneOut, cross_val_score, cross_validate,\n",
        "    GridSearchCV\n",
        ")\n",
        "\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, Normalizer,\n",
        "    PowerTransformer, QuantileTransformer, KBinsDiscretizer,\n",
        "    OneHotEncoder, OrdinalEncoder, LabelEncoder,\n",
        "    PolynomialFeatures\n",
        ")\n",
        "\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "\n",
        "from sklearn.feature_selection import (\n",
        "    SelectKBest, chi2, f_classif, f_regression, mutual_info_classif,\n",
        "    SelectFromModel, RFE, RFECV, VarianceThreshold\n",
        ")\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import (\n",
        "    PCA, TruncatedSVD, NMF, FastICA, SparsePCA, IncrementalPCA\n",
        ")\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import FeatureAgglomeration\n",
        "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
        "\n",
        "from sklearn.linear_model import (\n",
        "    LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, Lars, LassoLars,\n",
        "    SGDRegressor, SGDClassifier, LogisticRegression,\n",
        "    PassiveAggressiveClassifier, PassiveAggressiveRegressor,\n",
        "    HuberRegressor, RANSACRegressor, TheilSenRegressor,\n",
        "    Perceptron, QuantileRegressor\n",
        ")\n",
        "\n",
        "from sklearn.svm import (\n",
        "    SVC, SVR, LinearSVC, LinearSVR, OneClassSVM, NuSVC, NuSVR\n",
        ")\n",
        "\n",
        "from sklearn.neighbors import (\n",
        "    KNeighborsClassifier, KNeighborsRegressor, NearestNeighbors,\n",
        "    RadiusNeighborsClassifier, RadiusNeighborsRegressor,\n",
        "    LocalOutlierFactor, NeighborhoodComponentsAnalysis\n",
        ")\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor,\n",
        "    GradientBoostingClassifier, GradientBoostingRegressor,\n",
        "    HistGradientBoostingClassifier, HistGradientBoostingRegressor,\n",
        "    AdaBoostClassifier, AdaBoostRegressor,\n",
        "    BaggingClassifier, BaggingRegressor,\n",
        "    VotingClassifier, VotingRegressor,\n",
        "    StackingClassifier, StackingRegressor,\n",
        "    IsolationForest\n",
        ")\n",
        "\n",
        "from sklearn.cluster import (\n",
        "    KMeans, MiniBatchKMeans, DBSCAN, OPTICS, MeanShift,\n",
        "    AgglomerativeClustering, SpectralClustering,\n",
        "    AffinityPropagation, Birch\n",
        ")\n",
        "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
        "from sklearn.semi_supervised import LabelPropagation, LabelSpreading, SelfTrainingClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, balanced_accuracy_score,\n",
        "    precision_score, recall_score, f1_score, fbeta_score,\n",
        "    confusion_matrix, classification_report,\n",
        "    roc_auc_score, roc_curve, precision_recall_curve,\n",
        "    average_precision_score,\n",
        "    silhouette_score, davies_bouldin_score,\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    log_loss, brier_score_loss\n",
        ")\n",
        "from sklearn.utils import class_weight, resample, shuffle\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Демонстрационный вариант\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import (\n",
        "    load_diabetes,\n",
        "    load_breast_cancer,\n",
        "    load_wine,\n",
        "    load_digits,\n",
        ")\n",
        "\n",
        "# 1. Линейная регрессия на diabetes\n",
        "diabetes = load_diabetes()\n",
        "X_d, y_d = diabetes.data, diabetes.target\n",
        "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(\n",
        "    X_d, y_d, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train_d, y_train_d)\n",
        "r2 = r2_score(y_test_d, linreg.predict(X_test_d))\n",
        "print(\"1) R² (diabetes) =\", round(r2, 3))\n",
        "\n",
        "# 2. F1-score KNN на breast_cancer\n",
        "bc = load_breast_cancer()\n",
        "X_bc, y_bc = bc.data, bc.target\n",
        "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(\n",
        "    X_bc, y_bc, test_size=0.25, random_state=42, stratify=y_bc\n",
        ")\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_bc, y_train_bc)\n",
        "f1 = f1_score(y_test_bc, knn.predict(X_test_bc))\n",
        "print(\"2) F1 (breast cancer, KNN) =\", round(f1, 3))\n",
        "\n",
        "# 3. ROC AUC логистической регрессии\n",
        "logreg = LogisticRegression(max_iter=10_000)\n",
        "logreg.fit(X_train_bc, y_train_bc)\n",
        "proba = logreg.predict_proba(X_test_bc)[:, 1]\n",
        "roc = roc_auc_score(y_test_bc, proba)\n",
        "print(\"3) ROC AUC (breast cancer, LogReg) =\", round(roc, 3))\n",
        "\n",
        "# 4. SelectKBest на wine (k = 3)\n",
        "wine = load_wine()\n",
        "X_w, y_w = wine.data, wine.target\n",
        "skb = SelectKBest(score_func=f_classif, k=3).fit(X_w, y_w)\n",
        "sel_idx = skb.get_support(indices=True)\n",
        "sel_features = [wine.feature_names[i] for i in sel_idx]\n",
        "print(\"4) Лучшие признаки (wine) =\", \", \".join(sel_features))\n",
        "\n",
        "# 5. Pipeline: StandardScaler → PCA(3) → LogReg\n",
        "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(\n",
        "    X_w, y_w, test_size=0.25, random_state=42, stratify=y_w\n",
        ")\n",
        "\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"pca\", PCA(n_components=3)),\n",
        "        (\"logreg\", LogisticRegression(max_iter=10_000)),\n",
        "    ]\n",
        ")\n",
        "pipe.fit(X_train_w, y_train_w)\n",
        "acc = accuracy_score(y_test_w, pipe.predict(X_test_w))\n",
        "print(\"5) Accuracy (wine pipeline) =\", round(acc, 3))\n",
        "\n",
        "# 6. RandomForest + GridSearchCV\n",
        "param_grid = {\"n_estimators\": [10, 100], \"max_depth\": [3, 5]}\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "gs = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1)\n",
        "gs.fit(X_train_bc, y_train_bc)\n",
        "print(\"6) Лучший mean CV-score (RF) =\", round(gs.best_score_, 3))\n",
        "\n",
        "\n",
        "# 7. Кластеризация digits: PCA(2) → KMeans(10)\n",
        "digits = load_digits()\n",
        "X_digits = digits.data\n",
        "\n",
        "pca2 = PCA(n_components=2, random_state=42)\n",
        "X_digits_pca = pca2.fit_transform(X_digits)\n",
        "\n",
        "kmeans = KMeans(n_clusters=10, random_state=42)\n",
        "labels = kmeans.fit_predict(X_digits_pca)\n",
        "cluster0 = np.sum(labels == 0)\n",
        "print(\"7) Число точек в кластере 0 (digits) =\", cluster0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeBEAXweVdGK",
        "outputId": "5ffa8e82-d5a7-463c-f290-5e815b81da38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) R² (diabetes) = 0.485\n",
            "2) F1 (breast cancer, KNN) = 0.945\n",
            "3) ROC AUC (breast cancer, LogReg) = 0.996\n",
            "4) Лучшие признаки (wine) = flavanoids, od280/od315_of_diluted_wines, proline\n",
            "5) Accuracy (wine pipeline) = 0.956\n",
            "6) Лучший mean CV-score (RF) = 0.955\n",
            "7) Число точек в кластере 0 (digits) = 228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vj3bYBE8gQQE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}